{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimax Decoder - HaluEval Benchmark\n",
    "\n",
    "**Goal**: Run SmolLM2-360M + Minimax on HaluEval QA\n",
    "\n",
    "**Full dataset (10,000 samples) included - randomly samples 500 for benchmark**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q google-genai pydantic python-dotenv torch transformers accelerate groq huggingface-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU only'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set API key\n",
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_GEMINI_API_KEY_HERE\"  # <-- REPLACE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clone Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repo (HaluEval data is already included!)\n",
    "!git clone https://github.com/yourusername/minimax-decoder.git\n",
    "%cd minimax-decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify HaluEval data exists (full 10,000 samples)\n",
    "!wc -l data/HaluEval_QA.csv\n",
    "!head -2 data/HaluEval_QA.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Quick Test (10 random questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with 10 random questions\n",
    "!python benchmark.py -g smollm2-360m-local -a gemini-flash --data data/HaluEval_QA.csv --sample 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Full HaluEval Benchmark (500 random samples)\n",
    "\n",
    "**Estimated time: ~2-3 hours**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 500 random samples - SmolLM2 + Minimax\n",
    "# --sample 500 randomly selects from full 10,000 dataset\n",
    "# --seed 42 ensures reproducibility\n",
    "!python benchmark.py -g smollm2-360m-local -a gemini-flash \\\n",
    "    --data data/HaluEval_QA.csv \\\n",
    "    --sample 500 \\\n",
    "    --seed 42 \\\n",
    "    --output results/halueval_smollm2_minimax.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla baseline (no Minimax) - same 500 samples\n",
    "!python benchmark.py -g smollm2-360m-local --vanilla-only \\\n",
    "    --data data/HaluEval_QA.csv \\\n",
    "    --sample 500 \\\n",
    "    --seed 42 \\\n",
    "    --output results/halueval_smollm2_vanilla.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def show_results(path, name):\n",
    "    try:\n",
    "        with open(path) as f:\n",
    "            data = json.load(f)\n",
    "        m = data.get(\"metrics\", {})\n",
    "        print(f\"\\n=== {name} ===\")\n",
    "        print(f\"Questions: {m.get('total_questions', 'N/A')}\")\n",
    "        if \"minimax\" in m:\n",
    "            print(f\"Truthful: {m['minimax']['truthful_rate']*100:.1f}%\")\n",
    "            print(f\"Hallucination: {m['minimax']['hallucination_rate']*100:.1f}%\")\n",
    "            print(f\"Abstention: {m['minimax']['abstention_rate']*100:.1f}%\")\n",
    "        if \"vanilla\" in m:\n",
    "            print(f\"Vanilla Truthful: {m['vanilla']['truthful_rate']*100:.1f}%\")\n",
    "            print(f\"Vanilla Hallucination: {m['vanilla']['hallucination_rate']*100:.1f}%\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{name}: Not found yet\")\n",
    "\n",
    "show_results(\"results/halueval_smollm2_minimax.json\", \"HaluEval - SmolLM2 + Minimax\")\n",
    "show_results(\"results/halueval_smollm2_vanilla.json\", \"HaluEval - SmolLM2 Vanilla\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r halueval_results.zip results/\n",
    "print(\"Download halueval_results.zip from Output tab\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
