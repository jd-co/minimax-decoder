{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimax Decoder - HaluEval Benchmark\n",
    "\n",
    "**Goal**: Run SmolLM2-360M + Minimax on HaluEval QA (500 samples)\n",
    "\n",
    "**Second benchmark for your paper!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q google-genai pydantic python-dotenv torch transformers accelerate groq huggingface-hub datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU\n",
    "import torch\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU only'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set API key\n",
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_GEMINI_API_KEY_HERE\"  # <-- REPLACE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load HaluEval Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load HaluEval QA samples\n",
    "ds = load_dataset(\"pminervini/HaluEval\", \"qa_samples\", split=\"data\")\n",
    "print(f\"Total samples: {len(ds)}\")\n",
    "print(f\"Columns: {ds.column_names}\")\n",
    "print(f\"\\nExample:\")\n",
    "print(ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 500 questions\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "indices = random.sample(range(len(ds)), 500)\n",
    "sampled_data = ds.select(indices)\n",
    "print(f\"Sampled {len(sampled_data)} questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to our format (save as CSV for benchmark.py)\n",
    "import csv\n",
    "import os\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "with open(\"data/HaluEval_QA_500.csv\", \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Question\", \"Best Answer\", \"Correct Answers\", \"Incorrect Answers\", \"Category\", \"Knowledge\"])\n",
    "    \n",
    "    for item in sampled_data:\n",
    "        question = item[\"question\"]\n",
    "        knowledge = item[\"knowledge\"]\n",
    "        given_answer = item[\"answer\"]\n",
    "        is_hallucination = item[\"hallucination\"] == \"yes\"\n",
    "        \n",
    "        # Create question with context\n",
    "        full_question = f\"Based on the following information:\\n{knowledge}\\n\\nQuestion: {question}\"\n",
    "        \n",
    "        # If the given answer is NOT a hallucination, it's correct\n",
    "        if is_hallucination:\n",
    "            correct = \"Answer based only on the provided information.\"\n",
    "            incorrect = given_answer\n",
    "        else:\n",
    "            correct = given_answer\n",
    "            incorrect = \"Any answer not supported by the provided information.\"\n",
    "        \n",
    "        writer.writerow([full_question, correct, correct, incorrect, \"HaluEval-QA\", knowledge])\n",
    "\n",
    "print(\"Saved to data/HaluEval_QA_500.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clone Repo & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repo\n",
    "!git clone https://github.com/yourusername/minimax-decoder.git\n",
    "%cd minimax-decoder\n",
    "\n",
    "# Copy the HaluEval data we created\n",
    "!cp ../data/HaluEval_QA_500.csv data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quick Test (10 questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with 10 questions\n",
    "!python benchmark.py -g smollm2-360m-local -a gemini-flash --data data/HaluEval_QA_500.csv --limit 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Full HaluEval Benchmark (500 questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run full 500 questions - SmolLM2 + Minimax\n",
    "!python benchmark.py -g smollm2-360m-local -a gemini-flash \\\n",
    "    --data data/HaluEval_QA_500.csv \\\n",
    "    --limit 500 \\\n",
    "    --output results/halueval_smollm2_minimax.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla baseline\n",
    "!python benchmark.py -g smollm2-360m-local --vanilla-only \\\n",
    "    --data data/HaluEval_QA_500.csv \\\n",
    "    --limit 500 \\\n",
    "    --output results/halueval_smollm2_vanilla.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def show_results(path, name):\n",
    "    try:\n",
    "        with open(path) as f:\n",
    "            data = json.load(f)\n",
    "        m = data.get(\"metrics\", {})\n",
    "        print(f\"\\n=== {name} ===\")\n",
    "        print(f\"Questions: {m.get('total_questions', 'N/A')}\")\n",
    "        if \"minimax\" in m:\n",
    "            print(f\"Truthful: {m['minimax']['truthful_rate']*100:.1f}%\")\n",
    "            print(f\"Hallucination: {m['minimax']['hallucination_rate']*100:.1f}%\")\n",
    "        if \"vanilla\" in m:\n",
    "            print(f\"Vanilla Truthful: {m['vanilla']['truthful_rate']*100:.1f}%\")\n",
    "            print(f\"Vanilla Hallucination: {m['vanilla']['hallucination_rate']*100:.1f}%\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{name}: Not found yet\")\n",
    "\n",
    "show_results(\"results/halueval_smollm2_minimax.json\", \"HaluEval - SmolLM2 + Minimax\")\n",
    "show_results(\"results/halueval_smollm2_vanilla.json\", \"HaluEval - SmolLM2 Vanilla\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r halueval_results.zip results/\n",
    "print(\"Download halueval_results.zip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
